
2018-11

quartz+rabbitmq+zookeeper+nlog+elk

# 功能

通过算法对采集上来的数据进行规整。
1、把5分钟的数据规整成15分钟，对缺失的数据进行线性补充。等等。
2、数据缺失达到某种程度就不用进行修正了，而是打上标记
3、几百个楼宇，每个楼宇有上千个表，每个表有可能有多种类型的数据（有功电度、三相电压、三项电流等）
4、断数上传的情况下有可能会有几个表需要规整几个月的历史数据
规整任务是15分钟运行一次，如果出现断数上传，那程序会卡在那几个表上，而且单机程序应付不来这个计算量。
所以考虑使用rabbitmq来吧任务分发到多个机器上进行计算，15分钟发放一次任务。为了避免任务重新计算，比如说出现断数上传时，15分钟内还没算好某个表，又开始发放该表的计算任务，这时候需要避免新任务计算该表。所以这里需要用到锁。

分布式锁有redis、zookeeper
redis实现上比较繁琐，不支持断开连接后释放锁，这样可能造成某个表一直死锁。
所以考虑使用zookeeper

# 出现的难题

>数据库死锁

    有一个表在频繁插入数据，而项目中只是读取该表就发生了死锁
    
    查看死锁文件，是插入语句在获取到某个页的排他锁的同时，请求另一个页的排他锁，但是该页的共享锁被查询语句占用了，查询语句又请求已被插入语句死锁的页的共享锁，查询语句成了牺牲品。

    解决方案1：
    可以在查询语句中添加WITH (READPATH) ，表示如果需要查询的数据已经上了不兼容的锁，则跳过。
    不过该程序对数据实时性比较高，所以不适用
    解决方案2：加入重试机制
# 采用框架
程序:
rabbitmq+zookeeper
日志
nlog+logstash+elasticsearch+kibana


# rabbitmq


>四种exchange

direct、topic、headers、fanout

>BasicQos 

进行服务质量保证，即在非自动确认消息的前提下，如果一定数目的消息（通过基于consume或者channel设置Qos的值）未被确认前，不进行消费新的消息。

>ack确认

BasicNack 消费失败，重新入队  
BasicAck 消费成功，删除消息   

如果消费端与rabbitmq断开连接，没有进行确认的消息会重新入队

>BasicReject

放弃消息或者让消息重新入队

# zookeeper
>四种节点类型

>分布式锁实现

# logstash
>input、filter、output

>日志时间替换@timestamp

>自定义pattern

>分支结构（匹配异常处理）

>数据格式转换

>领域专用语言（domain specific language / DSL） 

# elasticsearch
>index

包括了类型名称

mapping --字段信息和字段类型，当类型字段更改时会自动更改索引信息，但是一个索引只有一个类型名称（看版本。）

>mapping

>几种数据类型

string、byte、short、integer、long、float、double、boolean、date
>x-pack

身份验证插件，在安装elasticsearch时会自动安装这个插件。


# kibana